{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation\n",
    "\n",
    "Data preparation : loading, cleaning, transforming, rearranging\n",
    "\n",
    "## 7.1 Handling Missing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data = pd.Series([\"aardvark\", np.nan, None, \"avocado\"])\n",
    "\n",
    "# Python's build in None value also been treated as NA\n",
    "string_data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = pd.Series([0, 1, 3, 0])\n",
    "\n",
    "num_data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out missing data\n",
    "\n",
    "data = pd.Series([1, np.nan, 3.5, np.nan, 7])\n",
    "\n",
    "# dropna by default drops any rows containing a missing value\n",
    "# use how=\"all\" will drop only rows that are all NA\n",
    "# use axis=\"columns\" to drop the column that contains NA value\n",
    "# thresh argument will keep only rows containing at most a certain number of missing observations \n",
    "data.dropna(how=\"all\")\n",
    "# Same as \n",
    "data[data.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling In Missing Data\n",
    "data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.standard_normal((7, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2:, 1] = np.nan\n",
    "df.iloc[4:, 2] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use different fill value for each column\n",
    "# ffill only works when at least the first row is not NA\n",
    "# df.fillna({1:0.5, 2:0})\n",
    "\n",
    "df.fillna(method=\"ffill\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Data Transformation\n",
    "\n",
    "### Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"k1\": [\"one\", \"two\"] * 3 + [\"two\"],\n",
    "\"k2\": [1,1,2,3,3,4,4]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicating whether each row is duplicated\n",
    "data.duplicated()\n",
    "\n",
    "# returns a dataframe with rows where the duplicated array is False filtered out\n",
    "# Subset will remove the duplicates for all the passed in columns\n",
    "# last will keep the last duplicated index instead first by default\n",
    "data.drop_duplicates(subset=[\"k1\", \"k2\"], keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming Data Using a Function or Mapping\n",
    "data = pd.DataFrame({\"food\": [\"bacon\", \"pulled prok\"], \"ounces\": [3, 4]})\n",
    "\n",
    "meat_to_animal = {\"bacon\": \"pig\", \"pulled pork\": \"pig\"}\n",
    "\n",
    "# Map method will map the key of the Series with the key of the passed in dictionary, and return the value\n",
    "data[\"animal\"] = data[\"food\"].map(meat_to_animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Values\n",
    "data = pd.Series([1, -999, 2, -999, -1000, 3])\n",
    "\n",
    "data.replace(-999, np.nan)\n",
    "\n",
    "# Replace multiple data at once\n",
    "data.replace([-999, -1000], np.nan)\n",
    "\n",
    "# use different replacement for each value\n",
    "data.replace([-999, -1000], [np.nan, 0])\n",
    "# or passin a dictionary\n",
    "data.replace({{-999:np.nan, -1000: 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Axis Indexes\n",
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)),\n",
    "index = [\"Ohio\", \"Colorado\", \"New York\"],\n",
    "columns = [\"one\", \"two\", \"three\", \"four\"]\n",
    ")\n",
    "\n",
    "def transform(x):\n",
    "\treturn x[:4].upper()\n",
    "\n",
    "data.index = data.index.map(transform)\n",
    "\n",
    "# Create a transformed version of a dataset without modifying the original\n",
    "data.rename(index=str.title, columns=str.upper)\n",
    "\n",
    "# Use in conjunction with a dictionary-like object\n",
    "data.rename(index={\"OHIO\": \"INDIANA\"}, columns={\"three\":\"peekabo\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization and Binning\n",
    "\n",
    "Continuous data is ofthen discretized or binned for analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = [20, 22, 25, 27, 21, 23, 27, 37, 31, 61, 45, 41, 32]\n",
    "\n",
    "bins = [18, 25, 35, 60, 100]\n",
    "\n",
    "# the bin computed by pandas.cut. \n",
    "age_categories = pd.cut(ages, bins)\n",
    "# Get the index number of the cutted sets in original data\n",
    "age_categories.codes\n",
    "\n",
    "age_categories.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parenthesis means the side is open and exclusive\n",
    "# square bracket means the side is closed, inclusive\n",
    "\n",
    "pd.cut(ages, bins, right=False)\n",
    "\n",
    "# Define a interval-based bin labeling\n",
    "group_names = [\"Youth\", \"YoungAdult\", \"MiddleAgend\", \"Senior\"]\n",
    "\n",
    "pd.cut(ages, bins, labels=group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.uniform(size = 20)\n",
    "\n",
    "# If pass an integer of bin, pandas will compute the equal-length bins based on the minimum and max values \n",
    "# precision=2 limits the decimal precision to two digits\n",
    "pd.cut(data, 4, precision=2)\n",
    "\n",
    "# pd.qcut bins the data based on sample quantiles\n",
    "pd.qcut(data, 4, precision=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting and Filtering Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.random.standard_normal((1000,4)))\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = data[2]\n",
    "\n",
    "# Find values in one of the columns exceeding 2.5 in absolute value\n",
    "col[col.abs() > 2.5]\n",
    "\n",
    "# To select all rows having a value exceeding 3 or -3\n",
    "# .any method can be used on boolean DataFrame\n",
    "data[(data.abs() > 3).any(axis='columns')]\n",
    "\n",
    "# Cap values outside of -2 or 2\n",
    "# np.sign() provide a -1 and 1 value based on the data\n",
    "data[data.abs()>2] = np.sign(data) * 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation and Random Sampling\n",
    "Permuting (randomly reordering) a Series or the rows in a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(5 * 7).reshape((5, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random the order of the DataFrame\n",
    "sampler = np.random.permutation(5)\n",
    "\n",
    "# Apply the random order to the DataFrame\n",
    "data.take(sampler)\n",
    "# Same as \n",
    "data.iloc[sampler]\n",
    "\n",
    "column_sampler = np.random.permutation(7)\n",
    "\n",
    "data.take(column_sampler, axis=\"columns\")\n",
    "\n",
    "# To select a random subset without replacement\n",
    "data.sample(n=3)\n",
    "\n",
    "# to generate a sample with replacement (to alow repeated choices) \n",
    "choices = pd.Series([5, 7, -1, 6, 4])\n",
    "choices.sample(n=10, replace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Indicator / Dummy Variables\n",
    "Convert a categorical variable in to a dummy or indicator matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"key\":[\"b\", \"b\", \"a\", \"c\", \"a\", \"b\"], \"data1\":range(6)})\n",
    "\n",
    "# Dummy variables\n",
    "dummies = pd.get_dummies(df[\"key\"], prefix=\"key\")\n",
    "\n",
    "# Join the dummy data\n",
    "df_with_dymmy = df[[\"data1\"]].join(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnames = [\"movie_id\", \"title\", \"genres\"]\n",
    "\n",
    "movies = pd.read_table(\n",
    "    \"./datasets/movielens/movies.dat\",\n",
    "    sep=\"::\",\n",
    "    header=None,\n",
    "    names=mnames,\n",
    "    engine=\"python\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummies if a row in a DataFrame belongs to multiple categories\n",
    "dummies = movies[\"genres\"].str.get_dummies(\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_windic = movies.join(dummies.add_prefix('Genre_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id                                       1\n",
       "title                           Toy Story (1995)\n",
       "genres               Animation|Children's|Comedy\n",
       "Genre_Action                                   0\n",
       "Genre_Adventure                                0\n",
       "Genre_Animation                                1\n",
       "Genre_Children's                               1\n",
       "Genre_Comedy                                   1\n",
       "Genre_Crime                                    0\n",
       "Genre_Documentary                              0\n",
       "Genre_Drama                                    0\n",
       "Genre_Fantasy                                  0\n",
       "Genre_Film-Noir                                0\n",
       "Genre_Horror                                   0\n",
       "Genre_Musical                                  0\n",
       "Genre_Mystery                                  0\n",
       "Genre_Romance                                  0\n",
       "Genre_Sci-Fi                                   0\n",
       "Genre_Thriller                                 0\n",
       "Genre_War                                      0\n",
       "Genre_Western                                  0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_windic.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0.0, 0.2]</th>\n",
       "      <th>(0.2, 0.4]</th>\n",
       "      <th>(0.4, 0.6]</th>\n",
       "      <th>(0.6, 0.8]</th>\n",
       "      <th>(0.8, 1.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   (0.0, 0.2]  (0.2, 0.4]  (0.4, 0.6]  (0.6, 0.8]  (0.8, 1.0]\n",
       "0           0           0           0           0           1\n",
       "1           0           1           0           0           0\n",
       "2           1           0           0           0           0\n",
       "3           0           1           0           0           0\n",
       "4           0           0           1           0           0\n",
       "5           0           0           1           0           0\n",
       "6           0           0           0           0           1\n",
       "7           0           0           0           1           0\n",
       "8           0           0           0           1           0\n",
       "9           0           0           0           1           0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine pandas.get_dummies with a discretization function likes pandas.clear_output\n",
    "np.random.seed(12345)\n",
    "\n",
    "values = np.random.uniform(size=10)\n",
    "\n",
    "values\n",
    "\n",
    "bins = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "# Return a dataframe with provided list value been categorized\n",
    "pd.get_dummies(pd.cut(values, bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8, 1.0], (0.2, 0.4], (0.0, 0.2], (0.2, 0.4], (0.4, 0.6], (0.4, 0.6], (0.8, 1.0], (0.6, 0.8], (0.6, 0.8], (0.6, 0.8]]\n",
       "Categories (5, interval[float64, right]): [(0.0, 0.2] < (0.2, 0.4] < (0.4, 0.6] < (0.6, 0.8] < (0.8, 1.0]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(values, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92961609, 0.31637555, 0.18391881, 0.20456028, 0.56772503,\n",
       "       0.5955447 , 0.96451452, 0.6531771 , 0.74890664, 0.65356987])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
