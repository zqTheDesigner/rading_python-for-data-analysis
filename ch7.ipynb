{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation\n",
    "\n",
    "Data preparation : loading, cleaning, transforming, rearranging\n",
    "\n",
    "## 7.1 Handling Missing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data = pd.Series([\"aardvark\", np.nan, None, \"avocado\"])\n",
    "\n",
    "# Python's build in None value also been treated as NA\n",
    "string_data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = pd.Series([0, 1, 3, 0])\n",
    "\n",
    "num_data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out missing data\n",
    "\n",
    "data = pd.Series([1, np.nan, 3.5, np.nan, 7])\n",
    "\n",
    "# dropna by default drops any rows containing a missing value\n",
    "# use how=\"all\" will drop only rows that are all NA\n",
    "# use axis=\"columns\" to drop the column that contains NA value\n",
    "# thresh argument will keep only rows containing at most a certain number of missing observations \n",
    "data.dropna(how=\"all\")\n",
    "# Same as \n",
    "data[data.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling In Missing Data\n",
    "data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.standard_normal((7, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2:, 1] = np.nan\n",
    "df.iloc[4:, 2] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use different fill value for each column\n",
    "# ffill only works when at least the first row is not NA\n",
    "# df.fillna({1:0.5, 2:0})\n",
    "\n",
    "df.fillna(method=\"ffill\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Data Transformation\n",
    "\n",
    "### Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"k1\": [\"one\", \"two\"] * 3 + [\"two\"],\n",
    "\"k2\": [1,1,2,3,3,4,4]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicating whether each row is duplicated\n",
    "data.duplicated()\n",
    "\n",
    "# returns a dataframe with rows where the duplicated array is False filtered out\n",
    "# Subset will remove the duplicates for all the passed in columns\n",
    "# last will keep the last duplicated index instead first by default\n",
    "data.drop_duplicates(subset=[\"k1\", \"k2\"], keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming Data Using a Function or Mapping\n",
    "data = pd.DataFrame({\"food\": [\"bacon\", \"pulled prok\"], \"ounces\": [3, 4]})\n",
    "\n",
    "meat_to_animal = {\"bacon\": \"pig\", \"pulled pork\": \"pig\"}\n",
    "\n",
    "# Map method will map the key of the Series with the key of the passed in dictionary, and return the value\n",
    "data[\"animal\"] = data[\"food\"].map(meat_to_animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Values\n",
    "data = pd.Series([1, -999, 2, -999, -1000, 3])\n",
    "\n",
    "data.replace(-999, np.nan)\n",
    "\n",
    "# Replace multiple data at once\n",
    "data.replace([-999, -1000], np.nan)\n",
    "\n",
    "# use different replacement for each value\n",
    "data.replace([-999, -1000], [np.nan, 0])\n",
    "# or passin a dictionary\n",
    "data.replace({{-999:np.nan, -1000: 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Axis Indexes\n",
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)),\n",
    "index = [\"Ohio\", \"Colorado\", \"New York\"],\n",
    "columns = [\"one\", \"two\", \"three\", \"four\"]\n",
    ")\n",
    "\n",
    "def transform(x):\n",
    "\treturn x[:4].upper()\n",
    "\n",
    "data.index = data.index.map(transform)\n",
    "\n",
    "# Create a transformed version of a dataset without modifying the original\n",
    "data.rename(index=str.title, columns=str.upper)\n",
    "\n",
    "# Use in conjunction with a dictionary-like object\n",
    "data.rename(index={\"OHIO\": \"INDIANA\"}, columns={\"three\":\"peekabo\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization and Binning\n",
    "\n",
    "Continuous data is ofthen discretized or binned for analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = [20, 22, 25, 27, 21, 23, 27, 37, 31, 61, 45, 41, 32]\n",
    "\n",
    "bins = [18, 25, 35, 60, 100]\n",
    "\n",
    "# the bin computed by pandas.cut. \n",
    "age_categories = pd.cut(ages, bins)\n",
    "# Get the index number of the cutted sets in original data\n",
    "age_categories.codes\n",
    "\n",
    "age_categories.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parenthesis means the side is open and exclusive\n",
    "# square bracket means the side is closed, inclusive\n",
    "\n",
    "pd.cut(ages, bins, right=False)\n",
    "\n",
    "# Define a interval-based bin labeling\n",
    "group_names = [\"Youth\", \"YoungAdult\", \"MiddleAgend\", \"Senior\"]\n",
    "\n",
    "pd.cut(ages, bins, labels=group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.uniform(size = 20)\n",
    "\n",
    "# If pass an integer of bin, pandas will compute the equal-length bins based on the minimum and max values \n",
    "# precision=2 limits the decimal precision to two digits\n",
    "pd.cut(data, 4, precision=2)\n",
    "\n",
    "# pd.qcut bins the data based on sample quantiles\n",
    "pd.qcut(data, 4, precision=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting and Filtering Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.random.standard_normal((1000,4)))\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = data[2]\n",
    "\n",
    "# Find values in one of the columns exceeding 2.5 in absolute value\n",
    "col[col.abs() > 2.5]\n",
    "\n",
    "# To select all rows having a value exceeding 3 or -3\n",
    "# .any method can be used on boolean DataFrame\n",
    "data[(data.abs() > 3).any(axis='columns')]\n",
    "\n",
    "# Cap values outside of -2 or 2\n",
    "# np.sign() provide a -1 and 1 value based on the data\n",
    "data[data.abs()>2] = np.sign(data) * 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation and Random Sampling\n",
    "Permuting (randomly reordering) a Series or the rows in a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(5 * 7).reshape((5, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random the order of the DataFrame\n",
    "sampler = np.random.permutation(5)\n",
    "\n",
    "# Apply the random order to the DataFrame\n",
    "data.take(sampler)\n",
    "# Same as \n",
    "data.iloc[sampler]\n",
    "\n",
    "column_sampler = np.random.permutation(7)\n",
    "\n",
    "data.take(column_sampler, axis=\"columns\")\n",
    "\n",
    "# To select a random subset without replacement\n",
    "data.sample(n=3)\n",
    "\n",
    "# to generate a sample with replacement (to alow repeated choices) \n",
    "choices = pd.Series([5, 7, -1, 6, 4])\n",
    "choices.sample(n=10, replace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Indicator / Dummy Variables\n",
    "Convert a categorical variable in to a dummy or indicator matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"key\":[\"b\", \"b\", \"a\", \"c\", \"a\", \"b\"], \"data1\":range(6)})\n",
    "\n",
    "# Dummy variables\n",
    "dummies = pd.get_dummies(df[\"key\"], prefix=\"key\")\n",
    "\n",
    "# Join the dummy data\n",
    "df_with_dymmy = df[[\"data1\"]].join(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnames = [\"movie_id\", \"title\", \"genres\"]\n",
    "\n",
    "movies = pd.read_table(\n",
    "    \"./datasets/movielens/movies.dat\",\n",
    "    sep=\"::\",\n",
    "    header=None,\n",
    "    names=mnames,\n",
    "    engine=\"python\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummies if a row in a DataFrame belongs to multiple categories\n",
    "dummies = movies[\"genres\"].str.get_dummies(\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_windic = movies.join(dummies.add_prefix('Genre_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_windic.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pandas.get_dummies with a discretization function likes pandas.clear_output\n",
    "np.random.seed(12345)\n",
    "\n",
    "values = np.random.uniform(size=10)\n",
    "\n",
    "values\n",
    "\n",
    "bins = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "# Return a dataframe with provided list value been categorized\n",
    "pd.get_dummies(pd.cut(values, bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(values, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Extension Data Types\n",
    "Extension type system, allowing for new data types to be added even if they are not supported natively by NumPy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, the series will be convert to float64 and np.nan for missing value\n",
    "s = pd.Series([1, 2, 3, None])\n",
    "\n",
    "# Create a series with pandas Int64Dtype\n",
    "s = pd.Series([1, 2, 3, None], dtype=pd.Int64Dtype())\n",
    "s\n",
    "\n",
    "# Missing vlaye will be use pandas.NA sentinel value\n",
    "s[3] is pd.NA\n",
    "\n",
    "# Sorthand for \"pd.Int64Dtype()\"\n",
    "s = pd.Series([1, 2, 3, None], dtype=\"Int64\")\n",
    "\n",
    "# String arrays use less memory and more efficient\n",
    "s = pd.Series([\"one\", \"two\", None, \"three\"], dtype=pd.StringDtype())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extention types can be passed to Series astype method\n",
    "\n",
    "df = pd.DataFrame({\"A\": [1, 2, None, 4],\n",
    "\"B\": [\"one\", \"two\", \"three\", None],\n",
    "\"C\": [False, None, False, True]\n",
    "})\n",
    "\n",
    "df[\"A\"] = df[\"A\"].astype('Int64')\n",
    "df[\"B\"] = df[\"B\"].astype(pd.StringDtype())\n",
    "df[\"C\"] = df[\"C\"].astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>three</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A      B      C\n",
       "0     1    one  False\n",
       "1     2    two   <NA>\n",
       "2  <NA>  three  False\n",
       "3     4   <NA>   True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 String Manipulation\n",
    "\n",
    "### Python Built-In String Object Methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = \"a,b, guido\"\n",
    "\n",
    "val.split(\",\")\n",
    "\n",
    "pieces = [x.strip() for x in val.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ab guido'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first, second, third = pieces\n",
    "\n",
    "first + \"::\" + second + \"::\" + third\n",
    "\n",
    "\"::\".join(pieces)\n",
    "\n",
    "\"guido\" in val\n",
    "\n",
    "# val.index(\",\")\n",
    "\n",
    "# difference between find() and index()\n",
    "# find() doesn't raise error\n",
    "val.find(\"asdf\")\n",
    "\n",
    "# index() will raise error if the element does not exist\n",
    "val.index(',')\n",
    "\n",
    "# count return the number or occurrences of a particular substring\n",
    "val.count(\",\")\n",
    "\n",
    "# Replace will substitute occurrences of one pattern for another\n",
    "val.replace(\",\", \"::\")\n",
    "\n",
    "# Also can be used to delete patterns by passing an empty string.\n",
    "val.replace(\",\", \"\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expressions\n",
    "\n",
    "The re module functions fall in to three categories: pattern matching, substitution, splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'bar', 'baz', 'qux']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"foo   bar\\t baz \\tqux\"\n",
    "\n",
    "# first complied and then split the passed text by white space characters\n",
    "re.split(r\"\\s+\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'bar', 'baz', 'qux']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same process as above\n",
    "regex = re.compile(r\"\\s+\")\n",
    "\n",
    "regex.split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['   ', '\\t ', ' \\t']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.findall(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a regex object with re.complie is highly recommended\n",
    "\n",
    "match and search are closely related to findall\n",
    "\n",
    "find all returns all mathes in a string. search returns only the first match.\n",
    "\n",
    "Match only matches at the buginning of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dave@google.com', 'steve@gmail.com', 'ryan@yahoo.com']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\" \n",
    "Dave dave@google.com\n",
    "Steve steve@gmail.com\n",
    "Ryan ryan@yahoo.com\n",
    "\"\"\"\n",
    "\n",
    "pattern = r\"[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}\"\n",
    "\n",
    "# re.IGNORECASE makes the regex case insensitive\n",
    "regex = re.compile(pattern, flags= re.IGNORECASE)\n",
    "\n",
    "regex.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(7, 22), match='dave@google.com'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only find the first match\n",
    "m = regex.search(text)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\nDave Redacted\\nSteve Redacted\\nRyan Redacted\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because the pattern is not matched start from beginning\n",
    "print(regex.match(text))\n",
    "\n",
    "# sub will return a new string with occurrences of the pattern replaced by a new string.\n",
    "regex.sub('Redacted', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find segment for each group\n",
    "pattern = r\"([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})\"\n",
    "\n",
    "regex = re.compile(pattern, flags=re.IGNORECASE)\n",
    "\n",
    "# text = \"wesm@bright.net\"\n",
    "m = regex.match(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dave', 'google', 'com'),\n",
       " ('steve', 'gmail', 'com'),\n",
       " ('ryan', 'yahoo', 'com')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.findall(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub has access to groups in each match using special symbold like \\1, \\2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String functions in pandas\n",
    "Clean up a messy dataset for analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Dave\": \"dave@google.com\", \"Steve\": \"steve@gmail.com\", \"Wes\": np.nan}\n",
    "\n",
    "data = pd.Series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     False\n",
       "Steve    False\n",
       "Wes       True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>dave</td>\n",
       "      <td>google</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steve</th>\n",
       "      <td>steve</td>\n",
       "      <td>gmail</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wes</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1     2\n",
       "Dave    dave  google   com\n",
       "Steve  steve   gmail   com\n",
       "Wes     <NA>    <NA>  <NA>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.str.contains('gmail')\n",
    "\n",
    "\n",
    "data_as_string = data.astype(\"string\")\n",
    "\n",
    "# use regular expression in string values\n",
    "data_as_string.str.findall(pattern, flags=re.IGNORECASE)\n",
    "\n",
    "# str.extract() will return an data frame\n",
    "data_as_string.str.extract(pattern, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dave     dave@google.com\n",
       "Steve    steve@gmail.com\n",
       "Wes                 <NA>\n",
       "dtype: string"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_as_string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
