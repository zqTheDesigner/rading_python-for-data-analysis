{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading, Storage, and File Formats\n",
    "Reading data and making it accessable - data loading. \n",
    "\n",
    "## 6.1 Reading and Writing data in Text Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use names to assign default column names\n",
    "# df = pd.read_csv('./datasets/ex1.csv', names=['a', 'b', 'c', 'd', 'message'])\n",
    "\n",
    "# header=None will ignore headers and use number to represent the column index\n",
    "# df = pd.read_csv('./datasets/ex1.csv', header=None)\n",
    "\n",
    "# Select one of the column as index label \n",
    "df=pd.read_csv('./datasets/ex1.csv', index_col=\"message\")\n",
    "\n",
    "# Hierarchical index\n",
    "# df = pd.read_csv(\"./datasets/csv_mindex.csv\", index_col=[\"key1\", \"key2\"])\n",
    "\n",
    "# If a table not have a fixed delimiter (example is a txt file, saperated by one or multiple white space)\n",
    "# Can also be read as csv\n",
    "# result = pd.read_csv(\"examples/ex3.txt\", sep=\"\\s+\")\n",
    "\n",
    "# If there are rows in the csv file that need to be skipped\n",
    "# pd.read_csv(\"./datasets/ex1.csv\", skiprows=[0, 2, 3])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep_default=False - don't auto convert to NA value, only convert nan valye based on the na_values\n",
    "#pd.read_csv(\"some-file\", keep_default=False, na_values=[\"NA\"])\n",
    "\n",
    "# For \"message\" column, foo and na will be converted to NaN, on \"something\" column, \"two\" will be converted to NaN\n",
    "sentinels = {\"message\": [\"foo\", \"na\"], \"something\":[\"two\"]}\n",
    "#pd.read_csv(\"some-example\", na_values=sentinels, keep_default_na=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some pandas.read_csv function arguments\n",
    "| Argument | Description |\n",
    "|-|-| \n",
    "| path | String indicating file system location |\n",
    "| sep or delimiter | character sequence used to split fields in each row |\n",
    "| header | Row number to use as column names, default is 0 |\n",
    "| index_col | Column numbers or names to use as the row index |\n",
    "| names | list of column names for result |\n",
    "| skiprows | number of rows at beginning of file to ignore or list of row numbers to skip |\n",
    "| na_values | Sequence of values to replace with NA. |\n",
    "| keep_default_na | whether to use the default NA value list or not |\n",
    "| comment | characters to split comments off the end of lines |\n",
    "| nrows | Number of rows to read from beginning of file |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = pd.read_csv(\"./datasets/ex1.csv\", chunksize=1000)\n",
    "\n",
    "tot = pd.Series([], dtype=\"int64\")\n",
    "# for piece in chunker:\n",
    "# \ttot = tot.add(piece[\"a\"].value_counts(), fill_value=0)\n",
    "\n",
    "for p in chunker:\n",
    "\tprint(p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data to text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    np.arange(20).reshape((4, 5)),\n",
    "    index=[\"a\", \"b\", \"c\", \"d\"],\n",
    "    columns=[\"u\", \"v\", \"w\", \"x\", \"y\"],\n",
    ")\n",
    "\n",
    "df[df<5].to_csv(\"./datasets/out.csv\", na_rep='ehhhh', sep=\"|\")\n",
    "\n",
    "\n",
    "# df.to_csv(\"./datasets/out.csv\", na_rep='ehhhh')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Other Delimited Formats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "\n",
    "with open(\"./datasets/ex7.csv\") as f:\n",
    "\tlines = list(csv.reader(f))\n",
    "\theader, values = lines[0], lines[1:]\n",
    "\n",
    "# Create a dictionary of data columns using da dictionary comprehension.\n",
    "data_dict = {h: v for h, v in zip(header, zip(*values))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [(\"a\",1), (\"b\",2)]\n",
    "\n",
    "# Reverse the iterable of tuples and 2 iterables\n",
    "list(zip(*lst))\n",
    "list(zip(('a', 'b'), (1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dialect(csv.Dialect):\n",
    "\tlineterminator= \"\\n\"\n",
    "\tdelimiter= \";\"\n",
    "\tquotechar= '\"'\n",
    "\tquoting = csv.QUOTE_ALL\n",
    "\n",
    "f =  open(\"./datasets/ex7.csv\")\n",
    "\n",
    "reader = csv.reader(f, dialect=my_dialect)\n",
    "\n",
    "list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to write delimited files manually\n",
    "with open(\"mydata.csv\", \"w\") as f:\n",
    "\twriter = csv.writer(f, dialect=my_dialect)\n",
    "\twriter.writerow((\"one\", \"two\", \"three\"))\n",
    "\twriter.writerow((\"1\", \"2\", 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "obj = \"\"\"\n",
    "{\"name\":\"Wes\", \"pet\":null }\n",
    "\"\"\"\n",
    "\n",
    "# Convert json string to dictionary\n",
    "result = json.loads(obj)\n",
    "\n",
    "result\n",
    "\n",
    "asjson = json.dumps(result)\n",
    "\n",
    "asjson\n",
    "\n",
    "# Save dataframe as json object\n",
    "df.to_json(sys.stdout)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML and HTML : Wbe Scraping\n",
    "\n",
    "pandas.read_html by default searches for and attempt to parse all tabular data contained within <table> tags\n",
    "The result is a list of DataFrame objects\n",
    "\n",
    "#### Parsing XML with lxml.objectify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify\n",
    "\n",
    "path = \"datasets/mta_perf/Performance_MNR.xml\"\n",
    "\n",
    "with open(path) as f:\n",
    "\tparsed = objectify.parse(f)\n",
    "\n",
    "# Get the root tag of the data set\n",
    "root =  parsed.getroot()\n",
    "\n",
    "root.tag\n",
    "\n",
    "data = []\n",
    "\n",
    "skip_fields = [\"PARENT_SEQ\", \"INDICATOR_SEQ\"]\n",
    "\n",
    "# Populate a dictionary of tag names to data values\n",
    "for elt in root.INDICATOR:\n",
    "\tel_data = {}\n",
    "\tfor child in elt.getchildren():\n",
    "\t\tif child.tag in skip_fields:\n",
    "\t\t\tcontinue\n",
    "\t\tel_data[child.tag] = child.pyval\n",
    "\tdata.append(el_data)\n",
    "\n",
    "# Convert the list of name to data values pair to data frame\n",
    "perf = pd.DataFrame(data)\n",
    "\n",
    "# Above is same as this one liner below\n",
    "pd.read_xml(\"./datasets/mta_perf/Performance_MNR.xml\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Binary Data Formats\n",
    "Store / serialize data in binary format by using Python's pickle module\n",
    "\n",
    "Pandas object all have a to_pickle method that writes the data to disk in pickle format\n",
    "\n",
    "### Using HDF5 Format\n",
    "HDF5 is intended to store large quantities of scientific array data. \n",
    "HDF - Hiearachical data format\n",
    "\n",
    "HDF5 is NOT a database, it is best suited for write-once, read-many datasets.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({\"a\": np.random.standard_normal(100)})\n",
    "\n",
    "store = pd.HDFStore(\"datasets/mydata.h5\")\n",
    "\n",
    "store['obj1'] = frame\n",
    "\n",
    "\n",
    "store[\"obj1_col\"] = frame[\"a\"]\n",
    "\n",
    "store['obj1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HTFStore supports \"fixed\" and \"table\" storage schemas\n",
    "\n",
    "store.put(\"obj2\", frame, format=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "store.select(\"obj2\", where=[\"index >= 10 and index <= 15\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Interacting with Wbe APIs\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"http://api.github.com/repos/pandas-dev/pandas/issues\"\n",
    "\n",
    "resp = requests.get(url)\n",
    "\n",
    "resp.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = resp.json()\n",
    "\n",
    "data[0]['title']\n",
    "\n",
    "issues = pd.DataFrame(data, columns=[\"number\", \"title\", \"labels\", \"state\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Interacting with Databases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQLite3 data base \n",
    "\n",
    "import sqlite3\n",
    "\n",
    "query = \"\"\"\n",
    "CREATE TABLE test\n",
    "(a VARCHAR(20), b VARCHAR(20), c REAL, d INTEGER)\n",
    "\"\"\"\n",
    "\n",
    "con = sqlite3.connect('mydata.sqlite')\n",
    "\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"Atlana\", \"Georgia\", 1.25, 6),\n",
    "\t\t\t\t(\"Tallahassee\", \"Florida\", 2.6, 3)\n",
    "]\n",
    "\n",
    "stmt = \"INSERT INTO test VALUES(?,?,?,?)\"\n",
    "\n",
    "con.executemany(stmt, data)\n",
    "\n",
    "cursor = con.execute(\"SELECT * FROM test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show each of the queried rows\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the columns\n",
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sqla\n",
    "\n",
    "db = sqla.create_engine(\"sqlite:///mydata.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args, kwargs = db.dialect.create_connect_args(db.url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT * FROM test\", db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db103a864d90754ea6859861b49c97228243503a9f70d5acb5594bb386424408"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
