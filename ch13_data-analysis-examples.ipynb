{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.1 Bitly Data from 1.USA.gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './datasets/bitly_usagov/example.txt'\n",
    "\n",
    "import json\n",
    "\n",
    "with open(path) as f:\n",
    "\trecords = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting Time Zones in Pure Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract timezones using list comprehension\n",
    "\n",
    "time_zones = [rec['tz'] for rec in records if 'tz' in rec]\n",
    "\n",
    "time_zones[:10]\n",
    "\n",
    "# Counts the timezone \n",
    "def get_counts(sequence):\n",
    "\tcounts = {}\n",
    "\tfor x in sequence:\n",
    "\t\tif x in counts:\n",
    "\t\t\tcounts[x] += 1\n",
    "\t\telse:\n",
    "\t\t\tcounts[x] = 1\n",
    "\treturn counts\n",
    "\n",
    "# Using more advanced python standard library\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_counts2(sequence):\n",
    "\tcounts = defaultdict(int) # Values will initialized to 0\n",
    "\tfor x in sequence:\n",
    "\t\tcounts[x] += 1\n",
    "\treturn counts\n",
    "\n",
    "counts = get_counts(time_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return top n counts \n",
    "def top_counts(count_dict, n=10):\n",
    "\tvalue_key_pairs = [(count, tz) for tz, count, in count_dict.items()]\n",
    "\tvalue_key_pairs.sort()\n",
    "\treturn value_key_pairs[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_counts(get_counts(time_zones), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Python standard library\n",
    "from collections import Counter\n",
    "\n",
    "counts = Counter(time_zones)\n",
    "counts.most_common(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Time Zones with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['tz'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_counts = frame['tz'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data using matplotlib\n",
    "\n",
    "# make the plots looks nicer by filling a substitute value for unknown value\n",
    "\n",
    "clean_tz = frame['tz'].fillna('Missing')\n",
    "\n",
    "clean_tz[clean_tz == \"\"] = \"Unknown\"\n",
    "\n",
    "tz_counts = clean_tz.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "subset = tz_counts.head()\n",
    "\n",
    "sns.barplot(y = subset.index, x = subset.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off the first token in the string and make another summary of the user behavior\n",
    "\n",
    "results = pd.Series([x.split()[0] for x in frame['a'].dropna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.value_counts().head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose the top timezones into Windows and non-Window users\n",
    "\n",
    "# Exclude missing agents from the data\n",
    "cframe = frame[frame['a'].notna()].copy()\n",
    "\n",
    "cframe['os'] = np.where(cframe['a'].str.contains('Windows'), 'Windows', 'Not Windows')\n",
    "\n",
    "cframe['os'].head()\n",
    "\n",
    "# Group the data by timezone column and list of os\n",
    "by_tz_os = cframe.groupby(['tz', 'os'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_counts = by_tz_os.size().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the top overall timezones\n",
    "\n",
    "# Construct an indirect index array from the row counts in agg_counts\n",
    "# After computing row counts with agg_counts.sum('columns'), use argosort() to obtain and index array\n",
    "indexer = agg_counts.sum('columns').argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use `take` to select the rows in the order. Slice off the last 10 rows (largest values)\n",
    "count_subset = agg_counts.take(indexer[-10:])\n",
    "\n",
    "count_subset\n",
    "\n",
    "# Use n-largest to achieve the same result\n",
    "agg_counts.sum(axis='columns').nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot in a grouped bar plot\n",
    "\n",
    "# First stack and reset the index to rearrange the data for better compatibility \n",
    "count_subset = count_subset.unstack()\n",
    "\n",
    "count_subset.name = 'total'\n",
    "\n",
    "count_subset = count_subset.reset_index()\n",
    "\n",
    "# sns.barplot(x = 'total', y = 'tz', hue = 'os', data=count_subset)\n",
    "\n",
    "# Normalize the group percentage sum to 1\n",
    "\n",
    "def normal_total(group):\n",
    "\tgroup['normed_total'] = group['total'] / group['total'].sum()\n",
    "\treturn group\n",
    "\n",
    "results = count_subset.groupby('tz').apply(normal_total)\n",
    "\n",
    "sns.barplot(x = 'normed_total', y='tz', hue='os', data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalized sum more efficiently using trans from groupby method\n",
    "\n",
    "g = count_subset.groupby('tz')\n",
    "results2 = count_subset['total'] / g['total'].transform['sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_subset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.2 MovieLens 1M Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unames = [\"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
    "\n",
    "users = pd.read_table(\n",
    "    \"datasets/movielens/users.dat\", sep=\"::\", header=None, names=unames, engine=\"python\"\n",
    ")\n",
    "\n",
    "rnames = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "\n",
    "ratings = pd.read_table(\n",
    "    \"datasets/movielens/ratings.dat\",\n",
    "    sep=\"::\",\n",
    "    header=None,\n",
    "    names=rnames,\n",
    "    engine=\"python\",\n",
    ")\n",
    "\n",
    "mnames = [\"movie_id\", \"title\", \"genres\"]\n",
    "movies = pd.read_table(\n",
    "    \"datasets/movielens/movies.dat\",\n",
    "    sep=\"::\",\n",
    "    header=None,\n",
    "    names=mnames,\n",
    "    engine=\"python\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'ratings' with 'users' and then merge that result with 'movies' data\n",
    "data = pd.merge(pd.merge(ratings, users), movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get mean movie ratings for each film grouped by gender\n",
    "\n",
    "mean_ratings = data.pivot_table('rating', index='title', columns='gender', aggfunc='mean')\n",
    "mean_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to movies that received at least 250 ratings\n",
    "\n",
    "ratings_by_title = data.groupby('title').size()\n",
    "\n",
    "active_titles = ratings_by_title.index[ratings_by_title >= 250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows from mean_ratings\n",
    "\n",
    "mean_ratings = mean_ratings.loc[active_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the top films among female viewers, sort F column in descending order\n",
    "\n",
    "top_female_ratings = mean_ratings.sort_values('F', ascending=False)\n",
    "\n",
    "top_female_ratings.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Rating Disagreement\n",
    "Find movies that are most divisive between male and female, add a column to mean_ratings contains the differences in means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratings['diff'] = mean_ratings['M'] - mean_ratings['F']\n",
    "\n",
    "sorted_by_diff = mean_ratings.sort_values('diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out movies that preferred by men that women didn't rated as highly\n",
    "sorted_by_diff[::-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the movies that elicited the most disagreement among viewers\n",
    "\n",
    "# Disagreement can be measured by the variance of standard deviation\n",
    "\n",
    "rating_std_by_title = data.groupby('title')['rating'].std()\n",
    "rating_std_by_title = rating_std_by_title.loc[active_titles]\n",
    "\n",
    "# Sort in descrending order and select the first 10 rows\n",
    "rating_std_by_title.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use `explode` method to group genres better\n",
    "movies['genres'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'].head().str.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the genres string into a list of genres \n",
    "movies['genre'] = movies.pop('genres').str.split('|')\n",
    "\n",
    "# Calling `explode` method to generate a new DataFrame with one row for each 'inner' element\n",
    "movies_exploded = movies.explode('genre')\n",
    "movies_exploded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all three tables together and group by genre\n",
    "\n",
    "rating_with_genre = pd.merge(pd.merge(movies_exploded, ratings),users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_ratings = (rating_with_genre.groupby(['genre', 'age'])['rating'].mean().unstack('age'))\n",
    "genre_ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db103a864d90754ea6859861b49c97228243503a9f70d5acb5594bb386424408"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
