{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.1 Bitly Data from 1.USA.gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './datasets/bitly_usagov/example.txt'\n",
    "\n",
    "import json\n",
    "\n",
    "with open(path) as f:\n",
    "\trecords = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting Time Zones in Pure Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract timezones using list comprehension\n",
    "\n",
    "time_zones = [rec['tz'] for rec in records if 'tz' in rec]\n",
    "\n",
    "time_zones[:10]\n",
    "\n",
    "# Counts the timezone \n",
    "def get_counts(sequence):\n",
    "\tcounts = {}\n",
    "\tfor x in sequence:\n",
    "\t\tif x in counts:\n",
    "\t\t\tcounts[x] += 1\n",
    "\t\telse:\n",
    "\t\t\tcounts[x] = 1\n",
    "\treturn counts\n",
    "\n",
    "# Using more advanced python standard library\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_counts2(sequence):\n",
    "\tcounts = defaultdict(int) # Values will initialized to 0\n",
    "\tfor x in sequence:\n",
    "\t\tcounts[x] += 1\n",
    "\treturn counts\n",
    "\n",
    "counts = get_counts(time_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return top n counts \n",
    "def top_counts(count_dict, n=10):\n",
    "\tvalue_key_pairs = [(count, tz) for tz, count, in count_dict.items()]\n",
    "\tvalue_key_pairs.sort()\n",
    "\treturn value_key_pairs[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_counts(get_counts(time_zones), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Python standard library\n",
    "from collections import Counter\n",
    "\n",
    "counts = Counter(time_zones)\n",
    "counts.most_common(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Time Zones with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['tz'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_counts = frame['tz'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data using matplotlib\n",
    "\n",
    "# make the plots looks nicer by filling a substitute value for unknown value\n",
    "\n",
    "clean_tz = frame['tz'].fillna('Missing')\n",
    "\n",
    "clean_tz[clean_tz == \"\"] = \"Unknown\"\n",
    "\n",
    "tz_counts = clean_tz.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "subset = tz_counts.head()\n",
    "\n",
    "sns.barplot(y = subset.index, x = subset.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off the first token in the string and make another summary of the user behavior\n",
    "\n",
    "results = pd.Series([x.split()[0] for x in frame['a'].dropna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.value_counts().head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose the top timezones into Windows and non-Window users\n",
    "\n",
    "# Exclude missing agents from the data\n",
    "cframe = frame[frame['a'].notna()].copy()\n",
    "\n",
    "cframe['os'] = np.where(cframe['a'].str.contains('Windows'), 'Windows', 'Not Windows')\n",
    "\n",
    "cframe['os'].head()\n",
    "\n",
    "# Group the data by timezone column and list of os\n",
    "by_tz_os = cframe.groupby(['tz', 'os'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_counts = by_tz_os.size().unstack().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the top overall timezones\n",
    "\n",
    "# Construct an indirect index array from the row counts in agg_counts\n",
    "# After computing row counts with agg_counts.sum('columns'), use argosort() to obtain and index array\n",
    "indexer = agg_counts.sum('columns').argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use `take` to select the rows in the order. Slice off the last 10 rows (largest values)\n",
    "count_subset = agg_counts.take(indexer[-10:])\n",
    "\n",
    "count_subset\n",
    "\n",
    "# Use n-largest to achieve the same result\n",
    "agg_counts.sum(axis='columns').nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot in a grouped bar plot\n",
    "\n",
    "# First stack and reset the index to rearrange the data for better compatibility \n",
    "count_subset = count_subset.unstack()\n",
    "\n",
    "count_subset.name = 'total'\n",
    "\n",
    "count_subset = count_subset.reset_index()\n",
    "\n",
    "# sns.barplot(x = 'total', y = 'tz', hue = 'os', data=count_subset)\n",
    "\n",
    "# Normalize the group percentage sum to 1\n",
    "\n",
    "def normal_total(group):\n",
    "\tgroup['normed_total'] = group['total'] / group['total'].sum()\n",
    "\treturn group\n",
    "\n",
    "results = count_subset.groupby('tz').apply(normal_total)\n",
    "\n",
    "sns.barplot(x = 'normed_total', y='tz', hue='os', data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalized sum more efficiently using trans from groupby method\n",
    "\n",
    "g = count_subset.groupby('tz')\n",
    "results2 = count_subset['total'] / g['total'].transform['sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_subset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.2 MovieLens 1M Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unames = [\"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
    "\n",
    "users = pd.read_table(\n",
    "    \"datasets/movielens/users.dat\", sep=\"::\", header=None, names=unames, engine=\"python\"\n",
    ")\n",
    "\n",
    "rnames = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "\n",
    "ratings = pd.read_table(\n",
    "    \"datasets/movielens/ratings.dat\",\n",
    "    sep=\"::\",\n",
    "    header=None,\n",
    "    names=rnames,\n",
    "    engine=\"python\",\n",
    ")\n",
    "\n",
    "mnames = [\"movie_id\", \"title\", \"genres\"]\n",
    "movies = pd.read_table(\n",
    "    \"datasets/movielens/movies.dat\",\n",
    "    sep=\"::\",\n",
    "    header=None,\n",
    "    names=mnames,\n",
    "    engine=\"python\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'ratings' with 'users' and then merge that result with 'movies' data\n",
    "data = pd.merge(pd.merge(ratings, users), movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get mean movie ratings for each film grouped by gender\n",
    "\n",
    "mean_ratings = data.pivot_table('rating', index='title', columns='gender', aggfunc='mean')\n",
    "mean_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to movies that received at least 250 ratings\n",
    "\n",
    "ratings_by_title = data.groupby('title').size()\n",
    "\n",
    "active_titles = ratings_by_title.index[ratings_by_title >= 250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows from mean_ratings\n",
    "\n",
    "mean_ratings = mean_ratings.loc[active_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the top films among female viewers, sort F column in descending order\n",
    "\n",
    "top_female_ratings = mean_ratings.sort_values('F', ascending=False)\n",
    "\n",
    "top_female_ratings.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Rating Disagreement\n",
    "Find movies that are most divisive between male and female, add a column to mean_ratings contains the differences in means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratings['diff'] = mean_ratings['M'] - mean_ratings['F']\n",
    "\n",
    "sorted_by_diff = mean_ratings.sort_values('diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out movies that preferred by men that women didn't rated as highly\n",
    "sorted_by_diff[::-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the movies that elicited the most disagreement among viewers\n",
    "\n",
    "# Disagreement can be measured by the variance of standard deviation\n",
    "\n",
    "rating_std_by_title = data.groupby('title')['rating'].std()\n",
    "rating_std_by_title = rating_std_by_title.loc[active_titles]\n",
    "\n",
    "# Sort in descrending order and select the first 10 rows\n",
    "rating_std_by_title.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use `explode` method to group genres better\n",
    "movies['genres'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'].head().str.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the genres string into a list of genres \n",
    "movies['genre'] = movies.pop('genres').str.split('|')\n",
    "\n",
    "# Calling `explode` method to generate a new DataFrame with one row for each 'inner' element\n",
    "movies_exploded = movies.explode('genre')\n",
    "movies_exploded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all three tables together and group by genre\n",
    "\n",
    "rating_with_genre = pd.merge(pd.merge(movies_exploded, ratings),users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_ratings = (rating_with_genre.groupby(['genre', 'age'])['rating'].mean().unstack('age'))\n",
    "genre_ratings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.3 US Baby Names 1880 - 2010 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Unix syntax to loot at first 10 lines of a file\n",
    "!head -n 10 'datasets/babynames/yob1880.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1880 = pd.read_csv('datasets/babynames/yob1880.txt', names = ['name', 'sex', 'births'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total number of both each year\n",
    "names1880.groupby('sex').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble all of the data into a single DataFrame \n",
    "\n",
    "pieces = []\n",
    "\n",
    "for year in range(1880, 2011):\n",
    "\tpath = f'datasets/babynames/yob{year}.txt'\n",
    "\tframe = pd.read_csv(path, names=['name', 'sex', 'births'])\n",
    "\n",
    "\t# Add a column of year\n",
    "\tframe['year'] = year\n",
    "\tpieces.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate everything into a single DataFrame\n",
    "names = pd.concat(pieces, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_births = names.pivot_table('births', index='year', columns='sex', aggfunc=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_births.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_births.plot(title='Total births by sex and year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a column prop with the fraction of babies given each name relative to the total number of birth\n",
    "# How popular the name is\n",
    "\n",
    "def add_prop(group):\n",
    "\tgroup['prop'] = group['births'] / group['births'].sum()\n",
    "\treturn group\n",
    "\n",
    "names = names.groupby(['year', 'sex']).apply(add_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to verify the prop will sum to 1\n",
    "names.groupby(['year', 'sex'])['prop'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a subset of the data to facilitate further analysis\n",
    "# Top 1000 names for each sex/year combination\n",
    "\n",
    "def get_top1000(group):\n",
    "\treturn group.sort_values('births', ascending=False)[:1000]\n",
    "\n",
    "grouped = names.groupby(['year', 'sex'])\n",
    "\n",
    "top1000 = grouped.apply(get_top1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000.head()\n",
    "\n",
    "# drop the group index \n",
    "top1000 = top1000.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Naming Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boys = top1000[top1000['sex']=='M']\n",
    "\n",
    "girls = top1000[top1000['sex']=='F']\n",
    "\n",
    "total_births = top1000.pivot_table('births', index='year', columns='name', aggfunc=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_births.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot names trends with DataFrame's plot method\n",
    "\n",
    "subset = total_births[['John', 'Harry', 'Mary', 'Marilyn']]\n",
    "\n",
    "subset.plot(subplots=True, figsize = (12, 10), title = 'Number of births per year')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuing the increase in naming diversity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of births represented by top 1000 most popular names\n",
    "\n",
    "table = top1000.pivot_table(\"prop\", index=\"year\", columns=\"sex\", aggfunc=sum)\n",
    "\n",
    "table.plot(title='Sum of table 1000.prop by year & sex', yticks=np.linspace(0, 1,2, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of distinct name taken in order of popularity from highest ot lowest]\n",
    "# boy names from 2010\n",
    "\n",
    "df = boys[boys['year'] == 2010]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many most popular name it takes to reach 50% \n",
    "\n",
    "prop_cumsum = df['prop'].sort_values(ascending=False).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cumsum[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchsorted method return the cumulative sum at provided value\n",
    "prop_cumsum.searchsorted(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = boys[boys['year'] == 1900]\n",
    "\n",
    "in1900 = df.sort_values('prop', ascending=False).prop.cumsum()\n",
    "\n",
    "in1900.searchsorted(0.5) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this operation to each year/sex combination\n",
    "\n",
    "def get_quantile_count(group, q=0.5):\n",
    "\tgroup = group.sort_values('prop', ascending=False)\n",
    "\treturn group.prop.cumsum().searchsorted(q) + 1\n",
    "\n",
    "diversity = top1000.groupby(['year', 'sex']).apply(get_quantile_count)\n",
    "\n",
    "diversity.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity.unstack().plot.line(title='Number of popular names in top 50%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 'last letter' revolution\n",
    "\n",
    "To see how the distribution of boy names' final letter has chaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_letter(x):\n",
    "    return x[-1]\n",
    "\n",
    "\n",
    "last_letters = names[\"name\"].map(get_last_letter)\n",
    "\n",
    "last_letters.name = \"last_letter\"\n",
    "\n",
    "table = names.pivot_table(\n",
    "    \"births\", index=last_letters, columns=[\"sex\", \"year\"], aggfunc=sum\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtable = table.reindex(columns=[1910, 1960, 2010], level='year')\n",
    "\n",
    "subtable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtable.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_prop = subtable / subtable.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "letter_prop[\"M\"].plot(kind='bar', rot=0, ax=axes[0], title='Male')\n",
    "letter_prop[\"F\"].plot(kind=\"bar\", rot=0, ax=axes[1], title='Female', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by year and sex and select a subset of letter for the boy names\n",
    "# transposing to make each column a time series\n",
    "\n",
    "letter_prop = table / table.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dny_ts = letter_prop.loc[['d', 'n', 'y'], 'M'].T\n",
    "\n",
    "dny_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dny_ts.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boy names that become girl names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = pd.Series(top1000['name'].unique())\n",
    "\n",
    "lesly_like = all_names[all_names.str.contains('Lesl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = top1000[top1000['name'].isin(lesly_like)]\n",
    "\n",
    "filtered.groupby('name')['births'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate by sex and year, normalize within year\n",
    "\n",
    "table = filtered.pivot_table(\"births\", index=\"year\", columns=\"sex\", aggfunc=\"sum\")\n",
    "\n",
    "table = table.div(table.sum(axis='columns'), axis='index')\n",
    "\n",
    "table.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.plot(style={'M':'k-', 'F':'k--'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.4 USDA Food Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file into python\n",
    "import json\n",
    "\n",
    "db = json.load(open(\"./datasets/usda_food/database.json\"))\n",
    "\n",
    "len(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[0]['nutrients'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients = pd.DataFrame(db[0]['nutrients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a list of dictionaries to a DataFrame\n",
    "\n",
    "info_keys = ['description', 'group', 'id', 'manufacturer']\n",
    "\n",
    "info = pd.DataFrame(db, columns=info_keys)\n",
    "\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(info['group'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse on all of the nutrient data\n",
    "# Assemble the nutrients for each food into a single large table\n",
    "\n",
    "# Convert each list of food nutrients to a dataFrame\n",
    "# add a column for food it\n",
    "# concatenate the data\n",
    "\n",
    "nutrients = []\n",
    "\n",
    "for rec in db:\n",
    "\tfnuts = pd.DataFrame(rec['nutrients'])\n",
    "\tfnuts['id'] = rec['id']\n",
    "\tnutrients.append(fnuts)\n",
    "\n",
    "nutrients = pd.concat(nutrients, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and drop the duplicates\n",
    "\n",
    "nutrients.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients = nutrients.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mapping = {\"description\": \"food\", \"group\": \"fgroup\"}\n",
    "\n",
    "info = info.rename(columns=col_mapping, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mapping = {'description':'nutrient', 'group':'nutgroup'}\n",
    "\n",
    "nutrients = nutrients.rename(columns=col_mapping, copy=False)\n",
    "\n",
    "nutrients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge info into nutrients\n",
    "ndata = pd.merge(nutrients, info, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata.iloc[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ndata.groupby(['nutrient', 'fgroup'])['value'].quantile(0.5)\n",
    "\n",
    "result['Zinc, Zn'].sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Zinc, Zn'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use idxmax or argmax Series method to find which food is most dense in each nutrient\n",
    "\n",
    "by_nutrient = ndata.groupby(['nutgroup', 'nutrient'])\n",
    "\n",
    "def get_maximum(x):\n",
    "\treturn x.loc[x.value.idxmax()]\n",
    "\n",
    "max_foods = by_nutrient.apply(get_maximum)[['value', 'food']]\n",
    "max_foods.loc['Amino Acids']['food']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.5 2012 Federal Election Commission Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fec = pd.read_csv('./datasets/fec/P00000001-ALL.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec.iloc[123456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ger the unique candidates\n",
    "unique_cands = fec['cand_nm'].unique()\n",
    "unique_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate party affiliation using dictionary\n",
    "parties = {\n",
    "  \"Bachmann, Michelle\": \"Republican\",\n",
    "  \"Cain, Herman\": \"Republican\",\n",
    "  \"Gingrich, Newt\": \"Republican\",\n",
    "  \"Huntsman, Jon\": \"Republican\",\n",
    "  \"Johnson, Gary Earl\": \"Republican\",\n",
    "  \"McCotter, Thaddeus G\": \"Republican\",\n",
    "  \"Obama, Barack\": \"Democratic\",\n",
    "  \"Pawlenty, Timothy\": \"Republican\",\n",
    "  \"Paul, Ron\": \"Republican\",\n",
    "  \"Perry, Rick\": \"Republican\",\n",
    "  \"Roemer, Charles E. 'Buddy' III\": \"Republican\",\n",
    "  \"Romney, Mitt\": \"Republican\",\n",
    "  \"Santorum, Rick\": \"Republican\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use map method to compute the parties by candidate name:\n",
    "fec['cand_nm'][123456:124361].map(parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec['party'] = fec['cand_nm'].map(parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fec['party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict the dataset to positive contributions\n",
    "fec = fec[fec['contb_receipt_amt'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cmte_id</th>\n",
       "      <th>cand_id</th>\n",
       "      <th>cand_nm</th>\n",
       "      <th>contbr_nm</th>\n",
       "      <th>contbr_city</th>\n",
       "      <th>contbr_st</th>\n",
       "      <th>contbr_zip</th>\n",
       "      <th>contbr_employer</th>\n",
       "      <th>contbr_occupation</th>\n",
       "      <th>contb_receipt_amt</th>\n",
       "      <th>contb_receipt_dt</th>\n",
       "      <th>receipt_desc</th>\n",
       "      <th>memo_cd</th>\n",
       "      <th>memo_text</th>\n",
       "      <th>form_tp</th>\n",
       "      <th>file_num</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>C00431171</td>\n",
       "      <td>P80003353</td>\n",
       "      <td>Romney, Mitt</td>\n",
       "      <td>ELDERBAUM, WILLIAM</td>\n",
       "      <td>DPO</td>\n",
       "      <td>AA</td>\n",
       "      <td>340230183</td>\n",
       "      <td>US GOVERNMENT</td>\n",
       "      <td>FOREIGN SERVICE OFFICER</td>\n",
       "      <td>25.0</td>\n",
       "      <td>01-FEB-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SA17A</td>\n",
       "      <td>780124</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>C00431171</td>\n",
       "      <td>P80003353</td>\n",
       "      <td>Romney, Mitt</td>\n",
       "      <td>ELDERBAUM, WILLIAM</td>\n",
       "      <td>DPO</td>\n",
       "      <td>AA</td>\n",
       "      <td>340230183</td>\n",
       "      <td>US GOVERNMENT</td>\n",
       "      <td>FOREIGN SERVICE OFFICER</td>\n",
       "      <td>110.0</td>\n",
       "      <td>01-FEB-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SA17A</td>\n",
       "      <td>780124</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>C00431171</td>\n",
       "      <td>P80003353</td>\n",
       "      <td>Romney, Mitt</td>\n",
       "      <td>CARLSEN, RICHARD</td>\n",
       "      <td>APO</td>\n",
       "      <td>AE</td>\n",
       "      <td>091280020</td>\n",
       "      <td>DEFENSE INTELLIGENCE AGENCY</td>\n",
       "      <td>INTELLIGENCE ANALYST</td>\n",
       "      <td>250.0</td>\n",
       "      <td>13-APR-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SA17A</td>\n",
       "      <td>785689</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>C00431171</td>\n",
       "      <td>P80003353</td>\n",
       "      <td>Romney, Mitt</td>\n",
       "      <td>DELUCA, PIERRE</td>\n",
       "      <td>APO</td>\n",
       "      <td>AE</td>\n",
       "      <td>091280005</td>\n",
       "      <td>CISCO</td>\n",
       "      <td>ENGINEER</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21-AUG-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SA17A</td>\n",
       "      <td>760261</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>C00431171</td>\n",
       "      <td>P80003353</td>\n",
       "      <td>Romney, Mitt</td>\n",
       "      <td>SARGENT, MICHAEL</td>\n",
       "      <td>APO</td>\n",
       "      <td>AE</td>\n",
       "      <td>090120092</td>\n",
       "      <td>RAYTHEON TECHNICAL SERVICES CORP</td>\n",
       "      <td>COMPUTER SYSTEMS ENGINEER</td>\n",
       "      <td>100.0</td>\n",
       "      <td>07-MAR-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SA17A</td>\n",
       "      <td>780128</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cmte_id    cand_id       cand_nm           contbr_nm contbr_city  \\\n",
       "411  C00431171  P80003353  Romney, Mitt  ELDERBAUM, WILLIAM         DPO   \n",
       "412  C00431171  P80003353  Romney, Mitt  ELDERBAUM, WILLIAM         DPO   \n",
       "413  C00431171  P80003353  Romney, Mitt    CARLSEN, RICHARD         APO   \n",
       "414  C00431171  P80003353  Romney, Mitt      DELUCA, PIERRE         APO   \n",
       "415  C00431171  P80003353  Romney, Mitt    SARGENT, MICHAEL         APO   \n",
       "\n",
       "    contbr_st contbr_zip                   contbr_employer  \\\n",
       "411        AA  340230183                     US GOVERNMENT   \n",
       "412        AA  340230183                     US GOVERNMENT   \n",
       "413        AE  091280020       DEFENSE INTELLIGENCE AGENCY   \n",
       "414        AE  091280005                             CISCO   \n",
       "415        AE  090120092  RAYTHEON TECHNICAL SERVICES CORP   \n",
       "\n",
       "             contbr_occupation  contb_receipt_amt contb_receipt_dt  \\\n",
       "411    FOREIGN SERVICE OFFICER               25.0        01-FEB-12   \n",
       "412    FOREIGN SERVICE OFFICER              110.0        01-FEB-12   \n",
       "413       INTELLIGENCE ANALYST              250.0        13-APR-12   \n",
       "414                   ENGINEER               30.0        21-AUG-11   \n",
       "415  COMPUTER SYSTEMS ENGINEER              100.0        07-MAR-12   \n",
       "\n",
       "    receipt_desc memo_cd memo_text form_tp  file_num       party  \n",
       "411          NaN     NaN       NaN   SA17A    780124  Republican  \n",
       "412          NaN     NaN       NaN   SA17A    780124  Republican  \n",
       "413          NaN     NaN       NaN   SA17A    785689  Republican  \n",
       "414          NaN     NaN       NaN   SA17A    760261  Republican  \n",
       "415          NaN     NaN       NaN   SA17A    780128  Republican  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sub set for the two main candidates\n",
    "fec_mrbo = fec[fec['cand_nm'].isin(['Obama, Barack', 'Romney, Mitt'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Donation statistics by Occupation and Employer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RETIRED                                   233990\n",
       "INFORMATION REQUESTED                      35107\n",
       "ATTORNEY                                   34286\n",
       "HOMEMAKER                                  29931\n",
       "PHYSICIAN                                  23432\n",
       "INFORMATION REQUESTED PER BEST EFFORTS     21138\n",
       "ENGINEER                                   14334\n",
       "TEACHER                                    13990\n",
       "CONSULTANT                                 13273\n",
       "PROFESSOR                                  12555\n",
       "NOT EMPLOYED                                9828\n",
       "SALES                                       8333\n",
       "LAWYER                                      8283\n",
       "MANAGER                                     8024\n",
       "PRESIDENT                                   7758\n",
       "STUDENT                                     7071\n",
       "OWNER                                       6343\n",
       "EXECUTIVE                                   5506\n",
       "SELF-EMPLOYED                               5472\n",
       "WRITER                                      5128\n",
       "SOFTWARE ENGINEER                           4960\n",
       "CEO                                         4932\n",
       "BUSINESS OWNER                              4380\n",
       "ACCOUNTANT                                  4175\n",
       "ARTIST                                      3724\n",
       "EDUCATOR                                    3576\n",
       "RN                                          3262\n",
       "REGISTERED NURSE                            3079\n",
       "INVESTOR                                    2708\n",
       "REAL ESTATE                                 2644\n",
       "FARMER                                      2597\n",
       "NONE                                        2571\n",
       "PSYCHOLOGIST                                2533\n",
       "SOCIAL WORKER                               2526\n",
       "UNEMPLOYED                                  2507\n",
       "DENTIST                                     2446\n",
       "CPA                                         2384\n",
       "ADMINISTRATOR                               2380\n",
       "ARCHITECT                                   2357\n",
       "PROJECT MANAGER                             2272\n",
       "DIRECTOR                                    2250\n",
       "REALTOR                                     2233\n",
       "REQUESTED                                   2196\n",
       "MARKETING                                   2134\n",
       "SCIENTIST                                   2095\n",
       "PHARMACIST                                  2056\n",
       "SOFTWARE DEVELOPER                          2048\n",
       "SELF                                        2047\n",
       "FINANCE                                     2001\n",
       "BANKER                                      1931\n",
       "VICE PRESIDENT                              1914\n",
       "DISABLED                                    1911\n",
       "NURSE                                       1899\n",
       "ANALYST                                     1889\n",
       "OFFICE MANAGER                              1886\n",
       "PROGRAMMER                                  1862\n",
       "MUSICIAN                                    1655\n",
       "CONTRACTOR                                  1612\n",
       "LIBRARIAN                                   1603\n",
       "C.E.O.                                      1594\n",
       "EXECUTIVE DIRECTOR                          1571\n",
       "PILOT                                       1478\n",
       "DESIGNER                                    1463\n",
       "EDITOR                                      1457\n",
       "COMPUTER PROGRAMMER                         1418\n",
       "SELF EMPLOYED                               1385\n",
       "FINANCIAL ADVISOR                           1349\n",
       "SMALL BUSINESS OWNER                        1344\n",
       "REAL ESTATE BROKER                          1314\n",
       "TRUCK DRIVER                                1277\n",
       "BOOKKEEPER                                  1253\n",
       "PSYCHOTHERAPIST                             1246\n",
       "IT                                          1159\n",
       "HOUSEWIFE                                   1114\n",
       "VETERINARIAN                                1106\n",
       "PARALEGAL                                   1101\n",
       "SECRETARY                                   1092\n",
       "INVESTMENTS                                 1090\n",
       "RETIRED TEACHER                             1070\n",
       "PHOTOGRAPHER                                1058\n",
       "CONSTRUCTION                                1056\n",
       "PARTNER                                     1031\n",
       "MANAGEMENT CONSULTANT                       1031\n",
       "MANAGEMENT                                  1028\n",
       "CFO                                         1014\n",
       "MD                                          1009\n",
       "ENTREPRENEUR                                 987\n",
       "TECHNICIAN                                   984\n",
       "ADMINISTRATIVE ASSISTANT                     969\n",
       "CHAIRMAN                                     967\n",
       "PROGRAM MANAGER                              952\n",
       "INFORMATION REQUESTED (BEST EFFORTS)         906\n",
       "ELECTRICIAN                                  902\n",
       "NURSE PRACTITIONER                           901\n",
       "R.N.                                         895\n",
       "SALES MANAGER                                895\n",
       "INSURANCE AGENT                              895\n",
       "DOCTOR                                       872\n",
       "GRAPHIC DESIGNER                             867\n",
       "PASTOR                                       866\n",
       "Name: contbr_occupation, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of donations by occupation\n",
    "pd.options.display.max_rows = 100\n",
    "fec['contbr_occupation'].value_counts()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_mapping = {'INFORMATION REQUESTED':'NOT PROVIDED', ''}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db103a864d90754ea6859861b49c97228243503a9f70d5acb5594bb386424408"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
