{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorizing a dataset and applying a function to each group. \n",
    "\n",
    "After lading, merging and preparing a dataset, you may need to compute statistics or possibly picot tables for reproting or visualization purpose. \n",
    "\n",
    "Use pandas `groupby` interface to slice, dice and summarize datasets\n",
    "\n",
    "- Split a pandas object into pieces using one or more keys\n",
    "- Calculate group summary statistics like count, mean or standard deviation\n",
    "- Apply within-group transformation or other manipulation like normalization, linear regression, rand or subset selection\n",
    "- Compute pivot tables and cross-tabulations\n",
    "- Perform quantile analysis and other statistical group analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.1 How to think about Group Operations\n",
    "\"split-apply-combine\" - group operations\n",
    "1. Data containes in a pandas object split into groups based on one or more keys that you provide, the splitting is performed on a particular axis of an object.\n",
    "2. A function applied to each group producting a new value. \n",
    "3. Finally, the results of all those function applications are combined into a result object. \n",
    "\n",
    "Each grouping key can take many forms, and they keu do not have to be all the same type. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GroupBy` object may looks like a DataFrame, but it is already grouped by the provided group key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"key1\": [\"a\", \"a\", None, \"b\", \"b\", \"a\", None],\n",
    "        \"key2\": pd.Series([1, 2, 1, 2, 1, None, 1], dtype=\"Int64\"),\n",
    "        \"data1\": np.random.standard_normal(7),\n",
    "        \"data2\": np.random.standard_normal(7),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compute the mean of data1 columns using the labels from key1\n",
    "# Will return the mean value of each group in \"key1\" (same key1 will be consider as 1 group)\n",
    "grouped = df['data1'].groupby(df['key1'])\n",
    "grouped.mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['key1']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df['data1'].groupby( df['key1']).mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df['data1'].groupby( df['key2']).mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df['data1'].groupby([df['key1'], df['key2']])\n",
    "means.head(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df['data1'].groupby([df['key1'], df['key2']]).mean()\n",
    "means.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.array(['OH', \"CA\", \"CA\", \"OH\", \"OH\", \"CA\", \"OH\"])\n",
    "\n",
    "years = [2005, 2005, 2006, 2005, 2006, 2005, 2006]\n",
    "\n",
    "# group keys can be any array of the right length.\n",
    "df['data1'].groupby([states, years]).mean().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass column names to use the column as the group keys\n",
    "\n",
    "df.groupby('key1').mean()\n",
    "\n",
    "df.groupby(['key1', 'key2']).mean().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['key1', 'key2']).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `GroupBy.size` method to return a Series containing group sizes. Any missing values in a group key are excluded from the result by default. This hebavior can be disabled by passing `dropna=False` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['key1', 'key2'], dropna=False).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key1').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key1', dropna=False).size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over Groups\n",
    "\n",
    "The object returned by groupby supposts iteration, generating a sequence of 2-tuples containing the group name along with the chunk of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df.groupby('key1'):\n",
    "\tprint(name)\n",
    "\tprint(group)\n",
    "\n",
    "# In the case of multiple keys, the first element in the tuple will be a tuple of key values\n",
    "for (k1, k2), group in df.groupby(['key1', 'key2']):\n",
    "\tprint((k1, k2))\n",
    "\tprint(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Computing a dictionary of data pieces as a one-linear\n",
    "pieces = {name: group for name, group in df.groupby(\"key1\")}\n",
    "\n",
    "pieces['b']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pieces['b']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group on any other axes \n",
    "\n",
    "Group df by whether they start with 'key' or 'data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(\n",
    "    {\"key1\": \"key\", \"key2\": \"key\", \"data1\": \"data\", \"data2\": \"data\"}, axis=\"columns\"\n",
    ")\n",
    "\n",
    "for group_key, group_val in grouped:\n",
    "\tprint(group_key)\n",
    "\tprint(group_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['data1','data2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['key1', 'key2']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a Column or Subset of Columns\n",
    "\n",
    "Indexing a GroupBy object created from a DataFrame with a column name or array of column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key1')['data1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data1'].groupby(df['key1']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To aggregate only a few columns\n",
    "# To only compute means for the data 2 column\n",
    "df.groupby(['key1', 'key2'])[['data2']].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping with Dictionaries and Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.DataFrame(\n",
    "    np.random.standard_normal((5, 5)),\n",
    "    columns=[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "    index=[\"Joe\", \"Steve\", \"Wanda\", \"Jill\", \"Trey\"],\n",
    ")\n",
    "\n",
    "people.iloc[2:3, [1,2]] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"a\": \"red\", \"b\": \"red\", \"c\": \"blue\", \"d\": \"blue\", \"e\": \"red\", \"f\": \"orange\"}\n",
    "\n",
    "by_column = people.groupby(mapping, axis=\"columns\")\n",
    "\n",
    "by_column.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_column.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_column.head(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_series = pd.Series(mapping)\n",
    "\n",
    "people.groupby(map_series, axis=\"columns\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping with Functions\n",
    "Any function passed as a group key will be called once per index value, with the return values being used as the group names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.groupby(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = ['one', 'one', 'one', 'two', 'two']\n",
    "\n",
    "people.groupby([len, key_list]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "people.groupby([len, key_list]).min()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by Index Levels\n",
    "Aggregate using one of the levles of an axis index. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.MultiIndex.from_arrays(\n",
    "    [[\"US\", \"US\", \"US\", \"JP\", \"JP\"], [1, 3, 5, 1, 3]], names=[\"city\", \"tenor\"]\n",
    ")\n",
    "\n",
    "hier_df = pd.DataFrame(np.random.standard_normal((4, 5)), columns=columns)\n",
    "\n",
    "hier_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To group by level, pass the level number or name using level keyword\n",
    "hier_df.groupby(level=\"city\", axis='columns').count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.2 Data Aggregation\n",
    "\n",
    "Aggregation refer to any data transformation that produces scalar values form arrays. \n",
    "\n",
    "Optimized groupby methods\n",
    "\n",
    "| Function Name | Description |\n",
    "| - | - |\n",
    "| any, all | return True is any (one or more values) or all none-Na values are \"truthy\" | \n",
    "| count | Number of non-NA values | \n",
    "| cumin, cummax | Cumulative minimum and maximum of no-NA values | \n",
    "| cumsum | Cumulative sum of non-NA values |\n",
    "| cumprod | Cumulative product of non-NA values |\n",
    "| first, last | First and last non-NA values |\n",
    "| mean | Mean of non-NA values |\n",
    "| median | Arithemetic median of non-NA values |\n",
    "| min, max | Minimum and maximum of non-NA values |\n",
    "| nth | Retrieve value that would appear at position n with the data in sorted order |\n",
    "| ohlc | Compute four \"open-high-low-close\" statistics for time series-like data. |\n",
    "| prod | product of non-NA values | \n",
    "| quantile | Compute sample quantile | \n",
    "| rand | Ordinal ranks of non-NA values, like calling Series.rank |\n",
    "| size | Compute group sizes, returning result as a Series | \n",
    "| std, var | Sample standard deviation and variance | \n",
    " \n",
    "\n",
    "Tp use your own aggregation functions, pass any function that aggregates an array to the aggregate methid or its short alias agg:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_to_peak(arr):\n",
    "\treturn arr.max() - arr.min()\n",
    "\n",
    "grouped.agg(peak_to_peak)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column-wise and multiple function application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = pd.read_csv('./datasets/tips.csv')\n",
    "\n",
    "tips.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips['tip_pct'] = tips['tip'] / tips['total_bill']\n",
    "\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = tips.groupby(['day', 'smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pct = grouped['tip_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pct.agg('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pct.agg(['mean', 'std', peak_to_peak])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass a list of (name, function) tuples, the first element of each tuple will be used as DataFrame column name\n",
    "grouped_pct.agg([('Average', 'mean'), ('stdev', np.std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a list of functions to apply to all of the columns or different functions per column in DataFrame\n",
    "functions = ['count', 'mean', 'max']\n",
    "\n",
    "result = grouped[['tip_pct', 'total_bill']].agg(functions)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different functions to one or more of the column, pass a dictionary to agg that contains a mapping of column names to any of the function specifications\n",
    "\n",
    "grouped.agg({\"tip\": np.max, \"size\": \"sum\"})\n",
    "\n",
    "# Pass multiple function to one column by using a list\n",
    "grouped.agg({\"tip_pct\": [\"min\", \"max\", \"mean\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.groupby(['day', 'smoker'], as_index=False).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.3 Apply: General split-apply-combine\n",
    "\n",
    "The most general purpose GroupBy method is apply. \n",
    "`apply` splits the object being manipulated into pieces, invokes the passed function on each piece and then attempts to concatenate the pieces. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that selects the rows with the largest values in a particular column\n",
    "def top(df, n=5, column=\"tip_pct\"):\n",
    "\treturn df.sort_values(column, ascending=False)[:n]\n",
    "\n",
    "top(tips, n=6)\n",
    "\n",
    "# The top function will be applied to each smoker group\n",
    "# The result has a hierarchical index with an inner level that contains index values from the original DataFrame\n",
    "tips.groupby('smoker').apply(top)\n",
    "\n",
    "# Pass a function to apply with other arguments\n",
    "# Below code will return the highest total bill in each day for smoker and non smokers\n",
    "tips.groupby(['smoker', 'day']).apply(top, n=1, column='total_bill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tips.groupby('smoker')['tip_pct'].describe()\n",
    "result\n",
    "result.unstack('smoker')\n",
    "# Inside groupby when invoke a method like describe, it is a sort cut for\n",
    "def f(group):\n",
    "\treturn group.describe()\n",
    "\n",
    "grouped.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppressing the Group Keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.groupby('smoker').apply(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.groupby('smoker', group_keys=False).apply(top)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile and Bucket Analysis\n",
    "`pandas.cut` and `pandas.qcut`, slicing data up into buckets with binds of your chooseing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample random dataset and an equal-length bucket categorization using pandas.cut\n",
    "frame = pd.DataFrame(\n",
    "    {\"data1\": np.random.standard_normal(1000), \"data2\": np.random.standard_normal(1000)}\n",
    ")\n",
    "\n",
    "frame.head()\n",
    "\n",
    "quartiles = pd.cut(frame['data1'], 4)\n",
    "\n",
    "# The Categorical object returned by cut can be passed directly to groupby. \n",
    "# So we could compute a set of group statistics fro the quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(group):\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"min\": group.min(),\n",
    "            \"max\": group.max(),\n",
    "            \"count\": group.count(),\n",
    "            \"mean\": group.mean(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "grouped = frame.groupby(quartiles)\n",
    "\n",
    "grouped.apply(get_stats)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Filling Missing Values with Group-Specific Values\n",
    "Suppose you need to fill value to vary by group.\n",
    "Use apply with function that calls fillna on each data chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['Ohio', 'New York', 'Vermont', 'Florida', 'Oregon', 'Nevada', 'California', 'Idaho']\n",
    "\n",
    "group_key = ['East', 'East', 'East', 'East', 'West', 'West', 'West', 'West']\n",
    "\n",
    "data = pd.Series(np.random.standard_normal(8), index=states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some value in the data to be missing\n",
    "data[['Vermont', 'Nevada', \"Idaho\"]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(group_key).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(group_key).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_mean(group):\n",
    "\treturn group.fillna(group.mean())\n",
    "\n",
    "data.groupby(group_key).apply(fill_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_values = {'East':0.5, 'West': -1}\n",
    "\n",
    "def fill_func(group):\n",
    "\treturn group.fillna(fill_values[group.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(group_key).apply(fill_func)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example : Random Sampling and Permutation\n",
    "\n",
    "To draw a random sample from a large dataset for Monte Carlo simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suits = [\"H\", \"S\", \"C\", \"D\"]\n",
    "\n",
    "card_val = (list(range(1, 11)) + [10] * 3) * 4\n",
    "base_names = [\"A\"] + list(range(2, 11)) + [\"J\", \"K\", \"Q\"]\n",
    "\n",
    "cards = []\n",
    "\n",
    "for suit in suits:\n",
    "\tcards.extend(str(num) + suit for num in base_names)\n",
    "\n",
    "deck = pd.Series(card_val, index=cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(deck, n = 5):\n",
    "\treturn deck.sample(5)\n",
    "\n",
    "draw(deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 2 random cards from each suit. \n",
    "\n",
    "def get_suit(card):\n",
    "\t# last letter is suit\n",
    "\treturn card[-1]\n",
    "\n",
    "deck.groupby(get_suit).apply(draw, n=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Group Weighted Average and Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"category\": [\"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\"],\n",
    "        \"data\": np.random.standard_normal(8),\n",
    "        \"weights\": np.random.uniform(size=8),\n",
    "    }\n",
    ")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"category\")\n",
    "\n",
    "# Weighted average by category\n",
    "def get_wavg(group):\n",
    "    return np.average(group[\"data\"], weights=group[\"weights\"])\n",
    "\n",
    "\n",
    "grouped.apply(get_wavg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_px = pd.read_csv(\"./datasets/stock_px.csv\", parse_dates=True, index_col=0)\n",
    "\n",
    "close_px.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_px.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that computes the pair-wise correlation or each column with SPX column\n",
    "\n",
    "def spx_corr(group):\n",
    "\treturn group.corrwith(group['SPX'])\n",
    "\n",
    "# Compute percent change on the close_px using pct_change\n",
    "rets = close_px.pct_change().dropna()\n",
    "\n",
    "# Group these percent changes by year\n",
    "def get_year(x):\n",
    "\treturn x.year\n",
    "\n",
    "by_year = rets.groupby(get_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year.apply(spx_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute intercolumn correlations\n",
    "\n",
    "def corr_appl_msft(group):\n",
    "\treturn group['AAPL'].corr(group[\"MSFT\"])\n",
    "\n",
    "by_year.apply(corr_appl_msft)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Group-Wise Linear Regression\n",
    "\n",
    "Groupby can perform more complex group-wise statistical analysis, as long as the function returns a pandas object or scalar value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def regress(data, yvar=None, xvars=None):\n",
    "\tY = data[yvar]\n",
    "\tX = data[xvars]\n",
    "\tX['intercept'] = 1\n",
    "\tresult = sm.OLS(Y, X).fit()\n",
    "\treturn result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year.apply(regress, yvar='AAPL', xvars=['SPX'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 10.4 Group Transforms and \"Unwrapped\" GroupBys\n",
    "\n",
    "`transform` build in method. \n",
    "- Product a scalar value to be broadcast to the shape of the group\n",
    "- Product an object of the same shape as the input group\n",
    "- Must not mutate its input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key':['a', 'b', 'c'] * 4, 'value':np.arange(12.)})\n",
    "g = df.groupby('key')\n",
    "g.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product a series of the same shape as df['value] but with values replaced by the average grouped by 'key'\n",
    "\n",
    "def get_mean(group):\n",
    "\treturn group.mean()\n",
    "\n",
    "g.transform(get_mean)\n",
    "\n",
    "g.apply(get_mean)\n",
    "\n",
    "def times_two(group):\n",
    "\treturn group * 2\n",
    "\n",
    "g.transform(times_two)\n",
    "\n",
    "# Compute the ranks in descending order for each group \n",
    "def get_ranks(group):\n",
    "\treturn group.rank(ascending=False)\n",
    "\n",
    "g.transform(get_ranks)\n",
    "\n",
    "g.rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a group transformation function composed from simple aggregations\n",
    "def normalize(x):\n",
    "\treturn (x - x.mean()) / x.std()\n",
    "\n",
    "g.transform(normalize)\n",
    "\n",
    "# Use built-in aggregate functions\n",
    "g.transform('mean')\n",
    "\n",
    "# unwrapped group operation\n",
    "# Doing arithmetic between the outputs of multiple GroupBy operations\n",
    "# Instead of writing a function and passing it to groupby(...).apply\n",
    "normalized = (df['value'] - g.transform('mean')) / g.transform('std')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.5 Pivot Tables and Cross-tabulation\n",
    "\n",
    "A pivot table is a data summarization tool frequently found in spreadsheet programs and other data analysis software. \n",
    "\n",
    "It aggregates a table of data by one or more keys, arranging the data in a rectangle with some of the group keys.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_521407/768270246.py:5: FutureWarning: pivot_table dropped a column because it failed to aggregate. This behavior is deprecated and will raise in a future version of pandas. Select only the columns that can be aggregated.\n",
      "  tips.pivot_table(index=[\"day\", \"smoker\"])\n",
      "/tmp/ipykernel_521407/768270246.py:7: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  tips.groupby([\"day\", \"smoker\"]).mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Thur</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th>smoker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Dinner</th>\n",
       "      <th>No</th>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>9.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Lunch</th>\n",
       "      <th>No</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <td>19.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "day             Fri   Sat   Sun  Thur  All\n",
       "time   smoker                             \n",
       "Dinner No       3.0  45.0  57.0   1.0  106\n",
       "       Yes      9.0  42.0  19.0   NaN   70\n",
       "Lunch  No       1.0   NaN   NaN  44.0   45\n",
       "       Yes      6.0   NaN   NaN  17.0   23\n",
       "All            19.0  87.0  76.0  62.0  244"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips = pd.read_csv(\"./datasets/tips.csv\")\n",
    "\n",
    "tips[\"tip_pct\"] =  tips[\"tip\"] / tips['total_bill']\n",
    "\n",
    "tips.pivot_table(index=[\"day\", \"smoker\"])\n",
    "# Same as\n",
    "tips.groupby([\"day\", \"smoker\"]).mean()\n",
    "\n",
    "# Take the average of only tip_pct and size  and additionally group by time. \n",
    "# Put smoker in the table columns and time and day in the rows\n",
    "tips.pivot_table(index=[\"time\", \"day\"], columns=\"smoker\", values=[\"tip_pct\", \"size\"])\n",
    "\n",
    "# adding a All row and column labels \n",
    "# means without taking in to account smoker versus nonsmoker \n",
    "tips.pivot_table(index=[\"time\", \"day\"], columns=\"smoker\", values=[\"tip_pct\", \"size\"], margins=True)\n",
    "\n",
    "# To use an aggregation function other than mean, pass it to aggfunc keyword argument\n",
    "tips.pivot_table(index=['time', 'smoker'], columns=\"day\", values=\"tip_pct\", aggfunc=len, margins=True)\n",
    "\n",
    "# use fill_value=0 argument to full up NA values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Tabulations: Crosstab\n",
    "\n",
    "a corss-tabulation is a special case of a pivot table that computes group frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "data = \"\"\"Sample Nationality Handedness\n",
    "1 USA Right-handed\n",
    "2 Japan Left-handed\n",
    "3 USA Right-handed\n",
    "4 Japan Right-handed\n",
    "5 Japan Left-handed\n",
    "6 Japan Right-handed\n",
    "7 USA Right-handed\n",
    "\"\"\"\n",
    "\n",
    "data = pd.read_table(StringIO(data), sep=\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smoker</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Dinner</th>\n",
       "      <th>Fri</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sat</th>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sun</th>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thur</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Lunch</th>\n",
       "      <th>Fri</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thur</th>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <td>151</td>\n",
       "      <td>93</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "smoker        No  Yes  All\n",
       "time   day                \n",
       "Dinner Fri     3    9   12\n",
       "       Sat    45   42   87\n",
       "       Sun    57   19   76\n",
       "       Thur    1    0    1\n",
       "Lunch  Fri     1    6    7\n",
       "       Thur   44   17   61\n",
       "All          151   93  244"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first two arguments to crosstab can each be an array of Series of a list of arrays\n",
    "pd.crosstab(data['Nationality'], data['Handedness'], margins=True)\n",
    "\n",
    "pd.crosstab([tips['time'], tips['day']], tips['smoker'], margins=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db103a864d90754ea6859861b49c97228243503a9f70d5acb5594bb386424408"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
